{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_feature(alg,dtrain,top=25):\n",
    "    feat_imp = pd.Series(alg.feature_importances_,index=dtrain.columns).sort_values(ascending=False)[0:top]\n",
    "    feat_imp.plot(kind='bar', title='top {} Feature Importances'.format(top))\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house=pd.read_csv(\"../data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date\n",
    "house['date']        =list(map(lambda strdate: datetime.strptime(strdate,'%Y%m%dT%H%M%S'), house['date']))\n",
    "house['sale_year']   =list(map(lambda date: date.year, house['date']))\n",
    "house['sale_month']  =list(map(lambda date: date.month,house['date']))\n",
    "house['sale_weekday']=list(map(lambda date: date.dayofweek,house['date'] ))\n",
    "# location \n",
    "house['zipcode']=house['zipcode'].astype('category')\n",
    "del house['id'] \n",
    "house['log_price']=np.log(house['price']) # log_normal distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = house.drop(columns=['price','log_price','date'])\n",
    "y_data = house['log_price']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_data,y_data,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine Model \n",
    "### 1. untuned tree-based model (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03658945029321862"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model=RandomForestRegressor()\n",
    "rf_model.fit(X_train,y_train)\n",
    "y_pred=rf_model.predict(X_test)\n",
    "mean_squared_error(y_test,y_pred) # untuned random forest results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. tunned linear model - Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** objective function**  :  $ \\frac{1}{2n} ||y - \\beta X||^2_2 + \\alpha* ratio * ||\\beta||_1  + 0.5 * \\alpha * (1 - ratio) * ||\\beta||^2_2  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x * L1 + y * L2 $$ \n",
    "$$\\alpha = x + y \\space and \\space ratio = \\frac{x}{  (x + y)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**alpha** control the total penalty for l2 and l1  \n",
    "**ratio** control the weight between l1 and l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=4)]: Done 101 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=4)]: Done 102 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=4)]: Done 103 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=4)]: Done 104 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=4)]: Done 106 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=4)]: Done 107 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=4)]: Done 108 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=4)]: Done 109 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=4)]: Done 110 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=4)]: Done 111 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=4)]: Done 112 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=4)]: Done 113 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=4)]: Done 114 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=4)]: Done 115 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=4)]: Done 116 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=4)]: Done 117 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=4)]: Done 118 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=4)]: Done 119 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=4)]: Done 121 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=4)]: Done 122 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=4)]: Done 123 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=4)]: Done 124 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=4)]: Done 125 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=4)]: Done 126 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=4)]: Done 127 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=4)]: Done 129 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=4)]: Done 131 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=4)]: Done 132 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=4)]: Done 133 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=4)]: Done 134 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=4)]: Done 135 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=4)]: Done 136 tasks      | elapsed:   40.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=4)]: Done 138 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=4)]: Done 139 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=4)]: Done 140 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=4)]: Done 141 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=4)]: Done 142 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=4)]: Done 143 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=4)]: Done 144 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=4)]: Done 145 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=4)]: Done 146 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=4)]: Done 147 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=4)]: Done 148 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=4)]: Done 149 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=4)]: Done 150 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=4)]: Done 151 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=4)]: Done 152 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=4)]: Done 153 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=4)]: Done 155 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=4)]: Done 156 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=4)]: Done 157 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=4)]: Done 158 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=4)]: Done 159 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=4)]: Done 160 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=4)]: Done 161 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=4)]: Done 162 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=4)]: Done 163 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=4)]: Done 164 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=4)]: Done 165 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=4)]: Done 166 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=4)]: Done 167 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=4)]: Done 168 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=4)]: Done 169 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=4)]: Done 170 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=4)]: Done 171 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=4)]: Done 172 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:   47.0s finished\n",
      "C:\\Wesley_Tao\\6.Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Wesley_Tao\\6.Software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: -0.26196, std: 0.00469, params: {'alpha': 0.01, 'fit_intercept': True, 'l1_ratio': 0.0, 'normalize': True},\n",
       "  mean: -0.06781, std: 0.00194, params: {'alpha': 0.01, 'fit_intercept': True, 'l1_ratio': 0.0, 'normalize': False},\n",
       "  mean: -0.27407, std: 0.00482, params: {'alpha': 0.01, 'fit_intercept': True, 'l1_ratio': 0.5, 'normalize': True},\n",
       "  mean: -0.06953, std: 0.00201, params: {'alpha': 0.01, 'fit_intercept': True, 'l1_ratio': 0.5, 'normalize': False},\n",
       "  mean: -0.27407, std: 0.00482, params: {'alpha': 0.01, 'fit_intercept': True, 'l1_ratio': 1, 'normalize': True},\n",
       "  mean: -0.07146, std: 0.00213, params: {'alpha': 0.01, 'fit_intercept': True, 'l1_ratio': 1, 'normalize': False},\n",
       "  mean: -0.13700, std: 0.00451, params: {'alpha': 0.01, 'fit_intercept': False, 'l1_ratio': 0.0, 'normalize': True},\n",
       "  mean: -0.13700, std: 0.00451, params: {'alpha': 0.01, 'fit_intercept': False, 'l1_ratio': 0.0, 'normalize': False},\n",
       "  mean: -0.13793, std: 0.00433, params: {'alpha': 0.01, 'fit_intercept': False, 'l1_ratio': 0.5, 'normalize': True},\n",
       "  mean: -0.13793, std: 0.00433, params: {'alpha': 0.01, 'fit_intercept': False, 'l1_ratio': 0.5, 'normalize': False},\n",
       "  mean: -0.13865, std: 0.00424, params: {'alpha': 0.01, 'fit_intercept': False, 'l1_ratio': 1, 'normalize': True},\n",
       "  mean: -0.13865, std: 0.00424, params: {'alpha': 0.01, 'fit_intercept': False, 'l1_ratio': 1, 'normalize': False},\n",
       "  mean: -0.27279, std: 0.00481, params: {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.0, 'normalize': True},\n",
       "  mean: -0.08800, std: 0.00227, params: {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.0, 'normalize': False},\n",
       "  mean: -0.27407, std: 0.00482, params: {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.5, 'normalize': True},\n",
       "  mean: -0.10887, std: 0.00246, params: {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 0.5, 'normalize': False},\n",
       "  mean: -0.27407, std: 0.00482, params: {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 1, 'normalize': True},\n",
       "  mean: -0.12453, std: 0.00253, params: {'alpha': 0.1, 'fit_intercept': True, 'l1_ratio': 1, 'normalize': False},\n",
       "  mean: -0.13886, std: 0.00432, params: {'alpha': 0.1, 'fit_intercept': False, 'l1_ratio': 0.0, 'normalize': True},\n",
       "  mean: -0.13886, std: 0.00432, params: {'alpha': 0.1, 'fit_intercept': False, 'l1_ratio': 0.0, 'normalize': False},\n",
       "  mean: -0.15767, std: 0.00369, params: {'alpha': 0.1, 'fit_intercept': False, 'l1_ratio': 0.5, 'normalize': True},\n",
       "  mean: -0.15767, std: 0.00369, params: {'alpha': 0.1, 'fit_intercept': False, 'l1_ratio': 0.5, 'normalize': False},\n",
       "  mean: -0.16651, std: 0.00363, params: {'alpha': 0.1, 'fit_intercept': False, 'l1_ratio': 1, 'normalize': True},\n",
       "  mean: -0.16651, std: 0.00363, params: {'alpha': 0.1, 'fit_intercept': False, 'l1_ratio': 1, 'normalize': False},\n",
       "  mean: -0.27343, std: 0.00482, params: {'alpha': 0.2, 'fit_intercept': True, 'l1_ratio': 0.0, 'normalize': True},\n",
       "  mean: -0.09347, std: 0.00233, params: {'alpha': 0.2, 'fit_intercept': True, 'l1_ratio': 0.0, 'normalize': False},\n",
       "  mean: -0.27407, std: 0.00482, params: {'alpha': 0.2, 'fit_intercept': True, 'l1_ratio': 0.5, 'normalize': True},\n",
       "  mean: -0.12469, std: 0.00252, params: {'alpha': 0.2, 'fit_intercept': True, 'l1_ratio': 0.5, 'normalize': False},\n",
       "  mean: -0.27407, std: 0.00482, params: {'alpha': 0.2, 'fit_intercept': True, 'l1_ratio': 1, 'normalize': True},\n",
       "  mean: -0.12545, std: 0.00248, params: {'alpha': 0.2, 'fit_intercept': True, 'l1_ratio': 1, 'normalize': False},\n",
       "  mean: -0.14115, std: 0.00424, params: {'alpha': 0.2, 'fit_intercept': False, 'l1_ratio': 0.0, 'normalize': True},\n",
       "  mean: -0.14115, std: 0.00424, params: {'alpha': 0.2, 'fit_intercept': False, 'l1_ratio': 0.0, 'normalize': False},\n",
       "  mean: -0.16653, std: 0.00364, params: {'alpha': 0.2, 'fit_intercept': False, 'l1_ratio': 0.5, 'normalize': True},\n",
       "  mean: -0.16653, std: 0.00364, params: {'alpha': 0.2, 'fit_intercept': False, 'l1_ratio': 0.5, 'normalize': False},\n",
       "  mean: -0.16614, std: 0.00363, params: {'alpha': 0.2, 'fit_intercept': False, 'l1_ratio': 1, 'normalize': True},\n",
       "  mean: -0.16614, std: 0.00363, params: {'alpha': 0.2, 'fit_intercept': False, 'l1_ratio': 1, 'normalize': False}],\n",
       " {'alpha': 0.01, 'fit_intercept': True, 'l1_ratio': 0.0, 'normalize': False},\n",
       " -0.06781044351344419)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "     \"alpha\":[0.01,0.1,0.2],\n",
    "    'l1_ratio':[0.0,0.5,1],\n",
    "    'fit_intercept': [True,False],\n",
    "    'normalize':[True,False]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = elastic_model, \n",
    "param_grid = param_test1, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5,verbose=20)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.01, copy_X=True, fit_intercept=True, l1_ratio=0.0,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_model.set_params(**gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Wesley_Tao\\6.Software\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06947561889100491"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_model.fit(X_train,y_train)\n",
    "y_pred=elastic_model.predict(X_test)\n",
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** objective function**  is L2 loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**: I: training data, d: iterations  \n",
    "**Input**: a: sampling ratio of large gradient data  \n",
    "**Input**: b: sampling ratio of small gradient data  \n",
    "**Input**: loss: loss function, L: weak learner  \n",
    "models ← {}, fact ← (1−a)/b  \n",
    "topN ← a × len(I) , randN ← b × len(I)  \n",
    "**for i = 1 to d do **  \n",
    "&ensp; preds ← models.predict(I)  \n",
    "&ensp; g ← loss(I, preds), w ← {1,1,...}  \n",
    "&ensp;  sorted ← GetSortedIndices(abs(g))  \n",
    "&ensp; topSet ← sorted[1:topN]  \n",
    "&ensp; randSet ← RandomPick(sorted[topN:len(I)],randN)  \n",
    "&ensp; usedSet ← topSet + randSet  \n",
    "&ensp; w[randSet] × = fact . Assign weight f act to the small gradient data.  \n",
    "&ensp; newModel ← L(I[usedSet], − g[usedSet],w[usedSet])  \n",
    "&ensp; models.append(newModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM offers good accuracy with integer-encoded categorical features.   \n",
    "LightGBM applies Fisher (1958) to find the optimal split over categories as described here. This often performs better than **one-hot encoding**.  \n",
    "\n",
    "**Categorical features** must be encoded as non-negative integers (int) less than Int32.MaxValue (2147483647). It is best to use a **contiguous range of integers**.  \n",
    "Use categorical_feature to specify the categorical features. Refer to the parameter categorical_feature in Parameters. \n",
    "\n",
    "Use **min_data_per_group, cat_smooth** to deal with over-fitting (when #data is small or #category is large).  \n",
    "\n",
    "For a categorical feature with high cardinality (#category is large), it often works best to treat the feature as numeric, either by simply ignoring the categorical interpretation of the integers or by embedding the categories in a low-dimensional numeric space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',\n",
       "       class_weight=None, colsample_bytree=1.0, learning_rate=0.1,\n",
       "       max_bin=100, max_depth=-1, metric='rmse', min_child_samples=20,\n",
       "       min_child_weight=0.001, min_data_in_leaf=80, min_split_gain=0.0,\n",
       "       n_estimators=3000, n_jobs=-1, num_leaves=50, objective=None,\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, save_binary=True,\n",
       "       silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "       subsample_freq=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model=LGBMRegressor()\n",
    "lgbm_params = {\n",
    "    \"n_estimators\":3000,\n",
    "    \"boosting_type\":\"gbdt\",\n",
    "#     \"application\":\"conitunous\",\n",
    "    \"learning_rate\":0.1, \n",
    "    \"min_data_in_leaf\":80, # dealt with overfiting\n",
    "    \"num_leaves\":50,\n",
    "#     \"min_data_per_group\":[10,30,50],\n",
    "#     \"cat_smooth\":[0,0.5,1],\n",
    "    \"max_depth\":-1,\n",
    "#     \"scale_pos_weight\":2,\n",
    "#     \"drop_rate\":0.02,\n",
    "    \"bagging_freq\":1,\n",
    "    \"bagging_fraction\":0.8,\n",
    "    \"metric\":\"rmse\",\n",
    "    \"min_split_gain\":0.0,\n",
    "#     \"colsample_bytree\":0.0\n",
    "    \"save_binary\":True,\n",
    "    \"max_bin\":100\n",
    "}\n",
    "lgb_model.set_params(**lgbm_params) #base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train = lgb.Dataset(data=X_train,\n",
    "                          label=y_train,\n",
    "#                           categorical_feature=cat_col,\n",
    "                          free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Wesley_Tao\\6.Software\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:394: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tcv_agg's l2: 0.0315795 + 0.0017749\n",
      "[100]\tcv_agg's l2: 0.0304633 + 0.00177822\n",
      "[150]\tcv_agg's l2: 0.0304682 + 0.00178045\n",
      "[200]\tcv_agg's l2: 0.030597 + 0.00178114\n",
      "[250]\tcv_agg's l2: 0.0307724 + 0.00169357\n",
      "[300]\tcv_agg's l2: 0.0309726 + 0.00173147\n"
     ]
    }
   ],
   "source": [
    "cv_results = lgb.cv(train_set=lgbm_train,\n",
    "                     params=lgbm_params,\n",
    "                     nfold=5,\n",
    "                     num_boost_round=1000,\n",
    "                     early_stopping_rounds=200,\n",
    "                     stratified=False,\n",
    "#                      objective=\"regression\",\n",
    "                     verbose_eval=50,\n",
    "                     metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum boost rounds = 122\n",
      "Best LGBM CV result = 0.03038865614705775\n"
     ]
    }
   ],
   "source": [
    "optimum_boost_rounds = np.argmin(cv_results['l2-mean'])\n",
    "print('Optimum boost rounds = {}'.format(optimum_boost_rounds))\n",
    "print('Best LGBM CV result = {}'.format(np.min(cv_results['l2-mean']))) #cv_agg's mape: 0.0418631 + 0.000355628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter tuning\n",
    "**max num_leaves**  This is the main parameter to control the complexity of the tree model.   \n",
    "Theoretically, we can set num_leaves = 2^(max_depth) to obtain the same number of leaves as depth-wise tree. \n",
    "\n",
    "**min_data_in_leaf** This is a very important parameter to prevent over-fitting in a leaf-wise tree.   \n",
    "Its optimal value depends on the number of training samples and num_leaves.   \n",
    "Setting it to a large value can avoid growing too deep a tree, but may cause under-fitting.   \n",
    "In practice, setting it to hundreds or thousands is enough for a large dataset.\n",
    "\n",
    "**max_depth. ** You also can use max_depth to limit the tree depth explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',\n",
       "       class_weight=None, colsample_bytree=1.0, learning_rate=0.1,\n",
       "       max_bin=100, max_depth=-1, metric='rmse', min_child_samples=20,\n",
       "       min_child_weight=0.001, min_data_in_leaf=80, min_split_gain=0.0,\n",
       "       n_estimators=122, n_jobs=-1, num_leaves=50, objective=None,\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, save_binary=True,\n",
       "       silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "       subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.set_params(n_estimators=122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=4)]: Done 101 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=4)]: Done 102 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=4)]: Done 103 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=4)]: Done 104 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=4)]: Done 106 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=4)]: Done 107 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=4)]: Done 108 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=4)]: Done 109 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=4)]: Done 110 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=4)]: Done 111 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=4)]: Done 112 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=4)]: Done 113 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=4)]: Done 114 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=4)]: Done 115 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=4)]: Done 116 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=4)]: Done 117 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=4)]: Done 118 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=4)]: Done 119 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=4)]: Done 121 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=4)]: Done 122 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=4)]: Done 123 tasks      | elapsed:   58.0s\n",
      "[Parallel(n_jobs=4)]: Done 124 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=4)]: Done 125 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=4)]: Done 126 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=4)]: Done 127 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=4)]: Done 128 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 129 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 130 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 131 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 132 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 133 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 134 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 135 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 136 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 138 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 139 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 140 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 141 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 142 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 143 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 144 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 145 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 146 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 147 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 148 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 149 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 150 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 151 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 152 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 153 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 155 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 156 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 157 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 158 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 159 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 160 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 161 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 162 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 163 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 164 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 165 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 166 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 167 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 168 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 169 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 170 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 171 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 172 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 174 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 175 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 176 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 177 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 178 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 179 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 180 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 181 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 182 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 183 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 185 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 186 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 187 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 188 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 189 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 190 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 191 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 193 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 194 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 195 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 196 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 197 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 198 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 199 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 200 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 201 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 202 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 203 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 204 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 205 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 206 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 207 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 208 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 209 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 210 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 211 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 212 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 214 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 215 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 216 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 217 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 218 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 225 out of 225 | elapsed:  1.8min finished\n",
      "C:\\Wesley_Tao\\6.Software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: -0.02796, std: 0.00053, params: {'cat_smooth': 0, 'min_data_in_leaf': 1, 'num_leaves': 10},\n",
       "  mean: -0.02657, std: 0.00057, params: {'cat_smooth': 0, 'min_data_in_leaf': 1, 'num_leaves': 30},\n",
       "  mean: -0.02667, std: 0.00074, params: {'cat_smooth': 0, 'min_data_in_leaf': 1, 'num_leaves': 50},\n",
       "  mean: -0.02772, std: 0.00027, params: {'cat_smooth': 0, 'min_data_in_leaf': 21, 'num_leaves': 10},\n",
       "  mean: -0.02665, std: 0.00052, params: {'cat_smooth': 0, 'min_data_in_leaf': 21, 'num_leaves': 30},\n",
       "  mean: -0.02640, std: 0.00089, params: {'cat_smooth': 0, 'min_data_in_leaf': 21, 'num_leaves': 50},\n",
       "  mean: -0.02772, std: 0.00040, params: {'cat_smooth': 0, 'min_data_in_leaf': 41, 'num_leaves': 10},\n",
       "  mean: -0.02640, std: 0.00027, params: {'cat_smooth': 0, 'min_data_in_leaf': 41, 'num_leaves': 30},\n",
       "  mean: -0.02628, std: 0.00043, params: {'cat_smooth': 0, 'min_data_in_leaf': 41, 'num_leaves': 50},\n",
       "  mean: -0.02781, std: 0.00033, params: {'cat_smooth': 0, 'min_data_in_leaf': 61, 'num_leaves': 10},\n",
       "  mean: -0.02654, std: 0.00028, params: {'cat_smooth': 0, 'min_data_in_leaf': 61, 'num_leaves': 30},\n",
       "  mean: -0.02633, std: 0.00042, params: {'cat_smooth': 0, 'min_data_in_leaf': 61, 'num_leaves': 50},\n",
       "  mean: -0.02874, std: 0.00044, params: {'cat_smooth': 0, 'min_data_in_leaf': 81, 'num_leaves': 10},\n",
       "  mean: -0.02752, std: 0.00057, params: {'cat_smooth': 0, 'min_data_in_leaf': 81, 'num_leaves': 30},\n",
       "  mean: -0.02731, std: 0.00045, params: {'cat_smooth': 0, 'min_data_in_leaf': 81, 'num_leaves': 50},\n",
       "  mean: -0.02804, std: 0.00057, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 1, 'num_leaves': 10},\n",
       "  mean: -0.02712, std: 0.00054, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 1, 'num_leaves': 30},\n",
       "  mean: -0.02714, std: 0.00091, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 1, 'num_leaves': 50},\n",
       "  mean: -0.02783, std: 0.00040, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 21, 'num_leaves': 10},\n",
       "  mean: -0.02680, std: 0.00037, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 21, 'num_leaves': 30},\n",
       "  mean: -0.02654, std: 0.00040, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 21, 'num_leaves': 50},\n",
       "  mean: -0.02775, std: 0.00037, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 41, 'num_leaves': 10},\n",
       "  mean: -0.02663, std: 0.00058, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 41, 'num_leaves': 30},\n",
       "  mean: -0.02651, std: 0.00044, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 41, 'num_leaves': 50},\n",
       "  mean: -0.02786, std: 0.00031, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 61, 'num_leaves': 10},\n",
       "  mean: -0.02674, std: 0.00026, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 61, 'num_leaves': 30},\n",
       "  mean: -0.02677, std: 0.00042, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 61, 'num_leaves': 50},\n",
       "  mean: -0.02869, std: 0.00024, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 81, 'num_leaves': 10},\n",
       "  mean: -0.02764, std: 0.00043, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 81, 'num_leaves': 30},\n",
       "  mean: -0.02776, std: 0.00045, params: {'cat_smooth': 0.5, 'min_data_in_leaf': 81, 'num_leaves': 50},\n",
       "  mean: -0.02808, std: 0.00058, params: {'cat_smooth': 1, 'min_data_in_leaf': 1, 'num_leaves': 10},\n",
       "  mean: -0.02704, std: 0.00065, params: {'cat_smooth': 1, 'min_data_in_leaf': 1, 'num_leaves': 30},\n",
       "  mean: -0.02717, std: 0.00074, params: {'cat_smooth': 1, 'min_data_in_leaf': 1, 'num_leaves': 50},\n",
       "  mean: -0.02787, std: 0.00033, params: {'cat_smooth': 1, 'min_data_in_leaf': 21, 'num_leaves': 10},\n",
       "  mean: -0.02684, std: 0.00037, params: {'cat_smooth': 1, 'min_data_in_leaf': 21, 'num_leaves': 30},\n",
       "  mean: -0.02682, std: 0.00049, params: {'cat_smooth': 1, 'min_data_in_leaf': 21, 'num_leaves': 50},\n",
       "  mean: -0.02782, std: 0.00038, params: {'cat_smooth': 1, 'min_data_in_leaf': 41, 'num_leaves': 10},\n",
       "  mean: -0.02666, std: 0.00048, params: {'cat_smooth': 1, 'min_data_in_leaf': 41, 'num_leaves': 30},\n",
       "  mean: -0.02679, std: 0.00043, params: {'cat_smooth': 1, 'min_data_in_leaf': 41, 'num_leaves': 50},\n",
       "  mean: -0.02790, std: 0.00033, params: {'cat_smooth': 1, 'min_data_in_leaf': 61, 'num_leaves': 10},\n",
       "  mean: -0.02673, std: 0.00046, params: {'cat_smooth': 1, 'min_data_in_leaf': 61, 'num_leaves': 30},\n",
       "  mean: -0.02675, std: 0.00020, params: {'cat_smooth': 1, 'min_data_in_leaf': 61, 'num_leaves': 50},\n",
       "  mean: -0.02894, std: 0.00033, params: {'cat_smooth': 1, 'min_data_in_leaf': 81, 'num_leaves': 10},\n",
       "  mean: -0.02777, std: 0.00038, params: {'cat_smooth': 1, 'min_data_in_leaf': 81, 'num_leaves': 30},\n",
       "  mean: -0.02769, std: 0.00039, params: {'cat_smooth': 1, 'min_data_in_leaf': 81, 'num_leaves': 50}],\n",
       " {'cat_smooth': 0, 'min_data_in_leaf': 41, 'num_leaves': 50},\n",
       " -0.026281361987260575)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "     \"num_leaves\":[10,30,50],\n",
    "    \"cat_smooth\":[0,0.5,1],\n",
    "    'min_data_in_leaf':list(range(1,100,20)) \n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = lgb_model, \n",
    "param_grid = param_test1, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5,verbose=20)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',\n",
       "       cat_smooth=0, class_weight=None, colsample_bytree=1.0,\n",
       "       learning_rate=0.1, max_bin=100, max_depth=-1, metric='rmse',\n",
       "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=41,\n",
       "       min_split_gain=0.0, n_estimators=122, n_jobs=-1, num_leaves=50,\n",
       "       objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "       save_binary=True, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.set_params(**gsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',\n",
       "       cat_smooth=0, class_weight=None, colsample_bytree=1.0,\n",
       "       learning_rate=0.1, max_bin=100, max_depth=-1, metric='rmse',\n",
       "       min_child_samples=20, min_child_weight=0.001, min_data_in_leaf=41,\n",
       "       min_split_gain=0.0, n_estimators=122, n_jobs=-1, num_leaves=50,\n",
       "       objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "       save_binary=True, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026607985573588906"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=lgb_model.predict(X_test)\n",
    "mean_squared_error(y_test,y_pred) # untuned random forest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAFICAYAAABKq2mSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c7288de828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature(lgb_model,dtrain=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important features\n",
    "# 1. Location (zip code latitude and longituted)\n",
    "# 2. square foot\n",
    "# 3. grade & condition \n",
    "# 4. Seasonality (seasonl sale)\n",
    "# 5. floor plan (eg 2b3b 2 floor)\n",
    "# 6. renovation\n",
    "# 7. view\n",
    "# 8. waterfront"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
